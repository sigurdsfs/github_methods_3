knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(readbulk, tidyverse, lmerTest, lme4, rstanarm)
df_exp <- readbulk::read_bulk("experiment_2", extension = ".csv")
knitr::opts_chunk$set(echo = TRUE)
df_exp1 <- readbulk::read_bulk("experiment 1", extension = ".csv")
set.seed(3215)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, lmerTest, lme4, stargazer, carret, readbulk, TinyTex, rstanarm, reabulk)
df_exp1 <- readbulk::read_bulk("experiment 1", extension = ".csv")
set.seed(3215)
sum(is.na(df_exp1$seed))
df_exp1 <- df_exp1 %>%
mutate(right_answer = if_else(target.type == "odd" & obj.resp == "o" | target.type == "even" & obj.resp == "e",1,0)) %>%
mutate(right_answer = as.numeric(right_answer))
df_exp1 <- df_exp1 %>%
mutate(right_answer = as.numeric(right_answer)) %>%
mutate(subject = as.factor(subject)) %>%
mutate(task = as.factor(task)) %>%
mutate(target.type = as.factor (target.type)) %>%
mutate(trial.type = as.factor(trial.type)) %>%
mutate(pas = as.factor(pas))
levels(df_exp1$trial.type)
df_exp1 <- df_exp1 %>%
filter(trial.type == "experiment")
summary(df_exp1$target.contrast)
m5.1.1 <- glmer(right_answer ~ target.frames + (1|subject)+ (1|trial), data = df_exp1, family = binomial(link = "logit"))
m5.1.2 <- glm(right_answer ~ target.frames, data = df_exp1, family = binomial(link = "logit"))
likelihood_function <- function(model, y){
p = fitted.values(model)
temp_vec = p^y*(1-p)^(1-y)
return(prod(temp_vec))
}
log_likelihood_function <- function(model, y){
p = fitted.values(model)
temp_vec = y * log(p) + (1-y) * log(1-p)
return(sum(temp_vec))
}
likelihood_function(m5.1.2, df_exp1$right_answer)
log_likelihood_function(m5.1.2, df_exp1$right_answer)
likelihood_function(m5.1.1, df_exp1$right_answer)
log_likelihood_function(m5.1.1, df_exp1$right_answer)
logLik(m5.1.1)
m5.2.1 <- glm(right_answer ~ 1, family = binomial(link = "logit"), data = df_exp1)
m5.2.2 <- glm(right_answer ~ target.frames , family = binomial(link= "logit"), data = df_exp1)
m5.2.3 <- glmer(right_answer ~ target.frames + (1|subject), family = binomial(link = "logit"), data = df_exp1)
m5.2.4 <- glmer(right_answer ~ target.frames  + (1+ target.frames|subject), family = binomial(link = "logit"), data = df_exp1)
summary(m5.2.4)
anova( m5.2.4, m5.2.3, m5.2.1, m5.2.3)
log_like_ratio_test <- function(model1, model2){
ratio = ifelse( logLik(model2) <= logLik(model1) , -2*(logLik(model2) - logLik(model1)) , (-2*(logLik(model1) - logLik(model2)))) #log-like-ratio
df_val = abs(df.residual(model1) - df.residual(model2)) #calculate the degree of freedom
p_val = pchisq(ratio, df = df_val, lower.tail = FALSE) #chi-square test
name = deparse(substitute(c(model1, model2)))
return(c(model_comp = name, log_lik_ratio = ratio, p_value = p_val))
}
log_like_ratio_test(m5.2.4, m5.2.1)
log_like_ratio_test(m5.2.4, m5.2.2)
log_like_ratio_test(m5.2.4, m5.2.3)
#With package
pacman::p_load(lmtest)
lrtest(m5.2.3 , m5.2.4)
newdata1 <- data.frame(target.frames = rep(seq(0,8,0.01),29) , subject = as.character(rep(seq(1:29),801))) %>%
mutate(subject = as.factor(subject))
#predict values for each subject target.frames 0:8
newdata1$yhat <- predict(m5.2.4, newdata = newdata1, type = "response")
ggplot(newdata1, aes(x = target.frames, y = yhat, color = subject)) + geom_line() +
ylim(0,1) + labs(title = "group-level function with individual slope and intercept", y = "% of right answer = 1")
ggplot(newdata1, aes(x = target.frames, y = yhat)) + geom_line(aes(colour = subject)) + labs(y = "predicted propability of right answer") +  facet_wrap(~subject) + xlim(0,8)
#get coef
coef_m5.2.4 <- coef(m5.2.4)
slope <- invlogit(coef_m5.2.4$subject[,2])
intercept <- invlogit(coef_m5.2.4$subject[,1])
cbind(intercept = summary(intercept), slope = summary(slope))
pacman::p_load(caret)
df_exp1<- df_exp1 %>%
mutate(fitted_m.5.2.4 = fitted(m5.2.4)) %>%
mutate(bin_fit_m5.2.4 = if_else(fitted_m.5.2.4 >= 0.5, 1, 0))
confusionMatrix(data = as.factor(df_exp1$bin_fit_m5.2.4), reference = as.factor(df_exp1$right_answer))
df_exp_temp <- df_exp1 %>%
group_by(subject) %>%
summarise(Percentage_correct_per_subject = sum(bin_fit_m5.2.4 == right_answer)/length(right_answer)*100)
ggplot(df_exp_temp, aes(x = subject, y = Percentage_correct_per_subject, fill = subject)) + geom_col()
df_exp1_fil24 <- df_exp1 %>%
filter(subject == 24)
#t-test on collected data
t.test(as.numeric(df_exp1_fil24$right_answer), mu = 0.5, alternative = "greater")
#t-test on predicted values.
t.test(as.numeric(df_exp1_fil24$bin_fit_m5.2.4), mu = 0.5, alternative = "greater")
m5.3.1 <- glmer(right_answer ~ pas*target.frames + (target.frames||subject), data = df_exp1, family = binomial(link = "logit"), control = glmerControl(optimizer="bobyqa"))
log_like_ratio_test(m5.3.1 , m5.2.4)
df_exp1 <- df_exp1 %>%
mutate(pred_interaction_model = fitted.values(m5.3.1))
interactions::interact_plot(model = m5.3.1 , pred = "target.frames", modx = "pas")
ggplot(df_exp1, aes(x = target.frames, y = pred_interaction_model, col = pas )) + geom_point() + facet_wrap(~subject) + xlim(0,8) + ylim(0,1)
summary(m5.3.1)
coef_OG_scale <-  data.frame(intercept = rep(NA,29), pas2 = rep(NA,29), pas3 = rep(NA,29), pas4 = rep(NA,29), target.frames = rep(NA,29), pas2_target.frames = rep(NA,29), pas3_target.frames = rep(NA,29), pas4_target.frames = rep(NA,29))
for (i in 1:length(coef(m5.3.1)$subject)){
coef_OG_scale[,i] = invlogit(coef(m5.3.1)$subject[,i])
}
coef(m5.3.1)
coef_OG_scale
design <- model.matrix(m5.3.1)
head(design)
pacman::p_load(multcomp)
contrast.vectors <- matrix(c(0, 0, 0, 0, -1, 1, 0, 0), nrow=1)
ghs <- glht(m5.3.1, contrast.vectors)
print(summary(ghs))
#Contrast matrix
contrast_matrix_compar <- glht(m5.3.1, linfct = c( "pas2:target.frames = -1", "pas3:target.frames = 1"))
summary(contrast_matrix_compar) #not a 100% how this works.
#Difference between pas2:target.frames pas3:target.frames
contrast.vector <- matrix(c(0, 0, 0, 0, 0, -1, 1, 0), nrow=1)
gh <- glht(m5.3.1, contrast.vector)
print(summary(gh))
#Difference between pas3:target.frames pas4:target.frames
contrast.vector2 <- matrix(c(0, 0, 0, 0, 0, 0, -1, 1), nrow=1)
gh2 <- glht(m5.3.1, contrast.vector2)
print(summary(gh2))
# beta = 0.44821   std.error =  0.03446 pas1-pas2
# beta = 0.005258   std.error = 0.073618 pas3-pas4
confint_gh<- confint(gh)
confint_gh2 <- confint(gh2)
df_confint <- data.frame(beta = c(confint_gh$confint[1], confint_gh2$confint[1]),
upper = c(confint_gh$confint[2], confint_gh2$confint[2]),
lower = c(confint_gh$confint[3], confint_gh2$confint[3]),
PAS1_2 = c(1,0),
PAS3_4 = c(0,1))
ggplot(df_confint, aes(x = PAS1_2, y = beta)) + geom_point() + geom_errorbar(aes(x = PAS1_2, ymin = lower, ymax = upper), width = 0.2, color = "red", size = 1)
RSS <- function(data, par)
{
## "dataset" should be a data.frame containing the variables x (target.frames)
## and y (correct)
## "par" are our four parameters (a numeric vector)
## par[1]=a, par[2]=b, par[3]=c, par[4]=d
a = par[1]
b = par[2]
c = par[3]
d = par[4]
x <- data$x
y <- data$y
y.hat <- a + ((b-a)/(1+(exp((c-x)/d))))
RSS <- sum((y - y.hat)^2)
return(RSS)
}
#Optim function with target.frames
data <- df_exp1 %>%
dplyr::select(target.frames, right_answer) %>%
rename(x = target.frames, y = right_answer)
optim(par = c(0.5,1,1,1), fn = RSS, data = data, method = "L-BFGS-B", lower = c(0.5,0.5,-Inf,-Inf),
upper = c(1,1,Inf,Inf))
#Optim function with pas rating.
data1 <- df_exp1 %>%
filter(subject == 7) %>% #only use subject 7
dplyr::select(pas, right_answer) %>%
mutate(pas = as.numeric(pas)) %>% #optim function requires it to be numeric.
rename(x = pas, y = right_answer)
optim_pas <- optim(par = c(0.5,1,1,1), fn = RSS, data = data1, method = "L-BFGS-B", lower = c(0.5,0.5,-Inf,-Inf),
upper = c(1,1,Inf,Inf))
optim_pas$par
sigmoid <- function(a,b, c,d,x){
y = a + ((b-a)/(1+(exp((c-x)/d))))
return(y)
}
x_pas_optim <- seq(0, 4, 0.01)
y_pas_optim <- sigmoid(optim_pas$par[1],optim_pas$par[2],
optim_pas$par[3],optim_pas$par[4],x_pas_optim)
plot(data1$x, data1$y, pch = 16, xlab = "Pas Rating", ylab = "% right answer = 1")
lines(x_pas_optim, y_pas_optim) + title(main = "Sigmoid function for pas-ratings.", sub = "plot1")
#Simple model to do illustrate pas ratings for subject 7
m7.1.1 <- glm(right_answer ~ as.numeric(pas), data = filter(df_exp1, subject == 7), family = binomial(link = "logit"))
x_pas <- seq(0, 4, 0.01)
y_pas <- predict(m7.1.1, list(pas = x_pas),type="response")
#plots for subject 7
plot(as.numeric(df_exp1$pas), df_exp1$right_answer, pch = 16, xlab = "Pas Rating", ylab = "% right answer = 1",
xlim = c(0,8)) + title(main = "subject 7 glm function with no interaction", sub = "plot 2")
lines(x_pas, y_pas)
newdat <- data.frame(cbind('target.frames' = seq(0, 8, by = 0.001), 'pas' = rep(1:4), 'subject' = rep('7')))
newdat$subject <- as.factor(newdat$subject)
newdat$pas <- as.factor(newdat$pas)
newdat$target.frames <- as.numeric(newdat$target.frames)
newdat$yhat <- predict(m5.3.1, newdata = newdat, type = "response")
ggplot(newdat, aes(x = target.frames, y = yhat, color = pas)) + geom_line() + labs(title = "Plot for subject 7, plot 4", y = "% of right_answer = 1")
#Create a function with a loop for calculating a,b,c and d for every subject within every level of PAS.
optim_for_indi <- function(){
data_frame_parameters <- data.frame(subject = NA, pas = NA , a = NA, b = NA, c = NA, d = NA)
for (i in 1:4){
df_temp1 <- df_exp1 %>%
filter(pas == i)
for (ii in 1:length(unique(df_exp1$subject))){
data_temp <- df_temp1 %>%
filter(subject == ii) %>%
dplyr::select(target.frames, right_answer, pas) %>%
rename(x = target.frames, y = right_answer)
op_temp = optim(par = c(0.5,0.5,1,1), fn = RSS, data = data_temp, method = "L-BFGS-B", lower = c(0.5,0.5,-Inf,-Inf),
upper = c(1,1,Inf,Inf))
data_frame_parameters <- rbind(data_frame_parameters , c(ii,i,op_temp$par))
}
}
return(data_frame_parameters)
}
#Get all parameters for each subject in each level of pas
df_param <- optim_for_indi() %>%
na.omit()
df_param
#Compute the average value of a,b,c and d.
df_param_avg <- df_param %>%
group_by(pas) %>%
summarise(a = mean(a), b = mean(b), c = mean(c), d = mean(d))
df_param_avg
#x-values
x_target.frames <- seq(0,8,0.01)
#setup data frame for x and y of different PAS score.
df_x_y <- data.frame(x_target.frames)
#Function for estimating y_hat given our a,b,c and d from our optim function.
y_hat_func <- function(){
for (i in 1:4){
y_hat_temp <- sigmoid(df_param_avg$a[i], df_param_avg$b[i], df_param_avg
$c[i], df_param_avg$d[i], x_target.frames)
df_x_y[,i+1] <- y_hat_temp
}
df_x_y <- df_x_y %>% #Rename column names into something meaningful.
rename(x = x_target.frames, y_hat_pas1 = V2 , y_hat_pas2 = V3 , y_hat_pas3 = V4 , y_hat_pas4 = V5)
return(df_x_y)
}
df_final_param <- y_hat_func()
head(df_final_param)
tail(df_final_param)
df_final_param_long <- df_final_param %>%
pivot_longer(cols = c(y_hat_pas1,y_hat_pas2,y_hat_pas3,y_hat_pas4) , names_to = "pas_name", values_to = "y_hat_merged")
df_final_param_long
ggplot(df_final_param_long, aes(x, y_hat_merged, colour = pas_name)) +
geom_line() + ylim(0,1) + labs(x = "target.frames", title = "averaged parameters across subject")
#Make function
optim_pas_overall <- function(i){
#prepare correct subset of  data frame.
pas_temp <- df_exp1 %>%
filter(pas == i) %>%
dplyr::select(target.frames, right_answer) %>%
rename(x = target.frames, y = right_answer)
op_temp_pas = optim(par = c(0.5,1,1,1), fn = RSS, data = pas_temp, method = "L-BFGS-B", lower =  c(0.5,0.5,-Inf,-Inf), upper = c(1,1,Inf,Inf))
# x and y values
x_pas_optim <- seq(0, 8, 0.01)
y_pas_optim <- sigmoid(op_temp_pas$par[1],op_temp_pas$par[2],
op_temp_pas$par[3],op_temp_pas$par[4],x_pas_optim)
return(y_pas_optim)
}
#Generate y_hats with function for all pas ratings.
data_frame_y_hats <- tibble(x = x_target.frames, y_hat_pas1 = optim_pas_overall(1)
, y_hat_pas2 = optim_pas_overall(2)
, y_hat_pas3 = optim_pas_overall(3)
, y_hat_pas4 = optim_pas_overall(4))
#Pivot longer to merge into 1 columns with an identity column.
data_frame_y_hats_long <- data_frame_y_hats %>%
pivot_longer(cols = c(y_hat_pas1,y_hat_pas2,y_hat_pas3,y_hat_pas4) , names_to = "pas_name", values_to = "y_hat_merged")
#plot
ggplot(data_frame_y_hats_long, aes(x, y_hat_merged, colour = pas_name)) +
geom_line() + ylim(0,1) + labs(x = "target.frames", title = "Parameters estimated grouped by PAS")
