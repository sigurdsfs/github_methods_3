---
title: "practical_exercise_2, Methods 3, 2021, autumn semester"
author: '[FILL IN YOUR NAME]'
date: '[FILL IN THE DATE]'
output:
  html_document:
    df_print: paged
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 1: Using mixed effects modelling to model hierarchical data
In this assignment we will be investigating the _politeness_ dataset of Winter and Grawunder (2012) and apply basic methods of multilevel modelling. 

```{r}
pacman::p_load(rstanarm, tidyverse, lmerTest, lme4)
pacman::p_load(MuMIn, effects)
```

## Dataset
The dataset has been shared on GitHub, so make sure that the csv-file is on your current path. Otherwise you can supply the full path.

```{r}
politeness <- read.csv('politeness.csv') ## read in data
```

# Exercises and objectives
The objectives of the exercises of this assignment are:  
1) Learning to recognize hierarchical structures within datasets and describing them 
2) Creating simple multilevel models and assessing their fitness  
3) Write up a report about the findings of the study  

REMEMBER: In your report, make sure to include code that can reproduce the answers requested in the exercises below  
REMEMBER: This assignment will be part of your final portfolio

## Exercise 1 - describing the dataset and making some initial plots

1) Describe the dataset, such that someone who happened upon this dataset could understand the variables and what they contain  

    i. Also consider whether any of the variables in _politeness_ should be encoded as factors or have the factor encoding removed. Hint: ```?factor```  
   
```{r}
summary(politeness)
```
```{r}
#Change variables to appropiate factors
politeness <- politeness %>% 
  mutate(scenario = as.factor(scenario)) %>% 
  mutate(gender = as.factor(gender)) %>% 
  mutate(attitude = as.factor(attitude))
head(politeness)
```
    
2) Create a new data frame that just contains the subject _F1_ and run two linear models; one that expresses _f0mn_ as dependent on _scenario_ as an integer; and one that expresses _f0mn_ as dependent on _scenario_ encoded as a factor.  

```{r}
politeness_F1 <- politeness %>% 
  filter(subject == "F1")
m1 <- lm(f0mn ~ scenario, data = politeness_F1)
m2 <- lm(f0mn ~ as.integer(scenario), data = politeness_F1)
```

    i. Include the model matrices, $X$ from the General Linear Model, for these two models in your report and describe the different interpretations of _scenario_ that these entail
# Scenario Encoded as Factor

```{r}
#Design Matrix
model.matrix(m1)
summary(m1)
```
The design matrix is a [14x7] matrix, so we will get the following $\beta_{0-6}$. 
This is also shown by the summary of a our linear regression model.
A simple regression f0mn ~ scenario was conducted. Scenario seemed to account
for 36.4% of the variance in f0mn following adjusted R^2. 
F(1,6) = 2.24, p >0.5) all beta values were insignificant. We only have 14
observations spread out over 7 different levels. So the high p-value is most likely
due to sample-size. A further power-analysis could show the required sample size required.
 
# Scenario Encoded as Int

```{r}
#Design Matrix
model.matrix(m2)
summary(m2)
```
Now that scenario is encoded as an integer the design matrix will be a [14x2] matrix.
Our model will therefore only give us $\beta_{0-1}$ and not a $\beta$ for each
level of scenario as done in the previous model. This model assumes that there is
a constant increment of f0mn following a "increase" in scenario (if you can even talk about
a unit increase of scenario). This would only make sense if scenarios were ordered
as getting harder and harder. The model is again f0mn ~ scenario 
F(1,12) = 2.231, p>0.5) with an adjusted $R^2$ = 0.0865 showing an explained
variance of 8.65% ($\beta_1$ = -6.886, SE = 4.6, t = -1.5, p>0.16.) Again such a
small sample size might be tricky to work with. 

    ii. Which coding of _scenario_, as a factor or not, is more fitting?
I would argue that scenario treated as a factor makes more sense. As mentioned 
a linear relationship between scenario number and f0mn does not make sense. 

Scenario's effect on f0mn in such a scenario as, Scenario[1] < Scenario[2] > Scenario[3].
Would not be possible to model having scenario as an integer. 

3) Make a plot that includes a subplot for each subject that has _scenario_ on the x-axis and _f0mn_ on the y-axis and where points are colour coded according to _attitude_
    i. Describe the differences between subjects
```{r}
ggplot(politeness, aes(x = scenario, y = f0mn, colour = attitude)) + geom_point()+
  facet_wrap(~subject)
```
There seem to be a lower baseline/intercept given that you're a male. Attitude doesn't
seem to have an large effect on f0mn. So an idea could be to add Gender as a
fixed effect and subject as a random intercept as there is also individual variance 
within the gender category. 
    
## Exercise 2  - comparison of models

For this part, make sure to have `lme4` installed.  
You can install it using `install.packages("lme4")` and load it using `library(lme4)`  
`lmer` is used for multilevel modelling
```{r, eval=FALSE}
mixed.model <- lmer(f0mn ~ scenario + gender + (1|subject), data=politeness)
```

1) Build four models and do some comparisons
    i. a single level model that models _f0mn_ as dependent on _gender_
```{r}
m3.1 <- lm(f0mn ~ gender, data = politeness)
```

    ii. a two-level model that adds a second level on top of i. where unique intercepts are modelled for each _scenario_
```{r}
m3.2 <- lmer(f0mn ~ gender + (1|scenario), data = politeness, REML = F)
```
    
    iii. a two-level model that only has _subject_ as an intercept 
```{r}
m3.3 <- lmer(f0mn ~ gender + (1|subject), data = politeness, REML = F)
summary(m3.3)
```

    iv. a two-level model that models intercepts for both _scenario_ and _subject_
```{r}
m3.4 <- lmer(f0mn ~ gender + (1|scenario) + (1|subject), data = politeness, REML = F)
summary(m3.4)
```


    v. which of the models has the lowest residual standard deviation, also compare the Akaike Information Criterion `AIC`?
```{r}
#Calculate Residual Standard Deivation
c(S_res1 = sqrt(sum(resid(m3.1)^2)/(nrow(politeness)-2)),  
S_res2 = sqrt(sum(resid(m3.2)^2)/(nrow(politeness)-2)),
S_res3 = sqrt(sum(resid(m3.3)^2)/(nrow(politeness)-2)),
S_res4 = sqrt(sum(resid(m3.4)^2)/(nrow(politeness)-2)))


#Compare AIC
AIC(m3.1,m3.2,m3.3,m3.4)
```
m3.4 is the model with the lowest residual standard deviation and also performs
the best following the AIC. 

    vi. which of the second-level effects explains the most variance?
```{r}
#Anova cannot compare multi-level and single-level models. :(
anova(m3.2,m3.3,m3.4)
```


```{r}
#Look for varaince explained
MuMIn::r.squaredGLMM(m3.2)
MuMIn::r.squaredGLMM(m3.3)
MuMIn::r.squaredGLMM(m3.4)
```
M3.2 (f0mn ~ gender + (1|scenario)) showed the best variance explained purely by
fixed effects. But m3.4 (f0mn ~ gender + (1|scenario) + (1|subject)) showed most
explained variance with 80% of the variance being accounted for from both fixed 
and random effects. 

We can also conclude that adding subject as random intercept rather than scenario
explains more of the variance but also has more shared variance with our fixed 
effect gender. 


2) Why is our single-level model bad?
    i. create a new data frame that has three variables, _subject_, _gender_ and _f0mn_, where _f0mn_ is the average of all responses of each subject, i.e. averaging across _attitude_ and_scenario_
```{r}
politeness_sel <- politeness %>%
  filter(!is.na(f0mn)) %>%
  group_by(subject) %>%
  summarise(f0mn = mean(f0mn))

politeness_sel <- politeness_sel %>% 
  mutate(gender = if_else(grepl("F", politeness_sel$subject, ignore.case = T),"F","M")) %>% 
  mutate(gender = as.factor(gender))
```

    ii. build a single-level model that models _f0mn_ as dependent on _gender_ using this new dataset
```{r}
m4.1 <- lm(f0mn ~ gender, data = politeness_sel)
```

    iii. make Quantile-Quantile plots, comparing theoretical quantiles to the sample quantiles) using `qqnorm` and `qqline` for the new single-level model and compare it to the old single-level model (from 1).i). Which model's residuals ($\epsilon$) fulfil the assumptions of the General Linear Model better?)
```{r}
#qqPlot
car::qqPlot(m4.1, main = "QQplot for the mean model")
car::qqPlot(m3.1, main = "QQplot for the normal model")
```
Both models residual distribution seems to be slighly heavy tailed. This could be
solved with a simple yuen trim of outliers. The first model 4.1 holds the assumptions
for the GLM better than the new model where f0mn is averaged. 

    iv. Also make a quantile-quantile plot for the residuals of the  multilevel model with two intercepts. Does it look alright?
    
```{r}
#car::qqPlot doesn't like mixed effect models so we do it like this. 
qqnorm(resid(m3.4))
qqline(resid(m3.4))


```

3) Plotting the two-intercepts model

    i. Create a plot for each subject, (similar to part 3 in Exercise 1), this time also indicating the fitted value for each of the subjects for each for the scenarios (hint use `fixef` to get the "grand effects" for each gender and `ranef` to get the subject- and scenario-specific effects)

```{r}
politeness_fil <- politeness %>%  #Remove NA's
    filter(!is.na(f0mn))

m3.5<- lmer(f0mn ~ scenario + attitude + (1|subject), data = politeness_fil)#new fit

politeness_fit <- politeness_fil %>% #Create data frame with fitted and actual values. 
  mutate(fitted_val = fitted.values(m3.5)) %>% 
  pivot_longer(cols = c(f0mn,fitted_val) , names_to = "prefix", values_to = "f0mn_merg")


ggplot(politeness_fit, aes(x = scenario, y = f0mn_merg, colour = prefix, shape = attitude)) + geom_point() + geom_smooth(method = "lm", se = F) +facet_wrap(~subject)
```

    
## Exercise 3 - now with attitude

1) Carry on with the model with the two unique intercepts fitted (_scenario_ and _subject_).
    i. now build a model that has _attitude_ as a main effect besides _gender_
```{r}
m5.1 <- lmer(f0mn ~ attitude + gender + (1|subject) + (1|scenario), data = politeness, REML = F)
```
    
    ii. make a separate model that besides the main effects of _attitude_ and _gender_ also include their interaction
```{r}
m5.2 <- lmer(f0mn ~ attitude*gender + (1|subject)+ (1|scenario), data = politeness, REML = F)
```

    iii. describe what the interaction term in the model says about Korean men's pitch when they are polite relative to Korean women's pitch when they are polite (you don't have to judge whether it is interesting)  
```{r}
summary(m5.2)
```

```{r}
MuMIn::r.squaredGLMM(m5.2)
levels(politeness$gender)
levels(politeness$attitude)
```
The model f0mn ~ attitude:gender + (1|subject)+ (1|scenario)has an $R^2c$ 0.81 both 
attitude and gender showed a significant effect on f0mn ($\beta_1$(attitude_pol) = -17.2, SE = 5.4,
p>0.05) and ($\beta_2$(genderM) = -119, SE = 12.8, p>0.05). Being polite and male 
lowers your frequency. Being both Male and Polite has an interaction effect of 
($\beta_3$ = 5.5, SE = 8.24, p<0.05). Hereby concluding that there is a small positive
insignificant interaction effect of being male and polite. The SE being proportional large
compared to the effect size makes it very difficult to say anything meaningfull. 

2) Compare the three models (1. gender as a main effect; 2. gender and attitude as main effects; 3. gender and attitude as main effects and the interaction between them. For all three models model unique intercepts for _subject_ and _scenario_) using residual variance, residual standard deviation and AIC.  

```{r}
#reidual variance 
c(RS_5.2 = sum(residuals(m5.2)^2),
RS_5.1 = sum(residuals(m5.1)^2),
RS_3.4 = sum(residuals(m3.4)^2))




#residual standard deviation
c(S_res5.2 = sqrt(sum(resid(m5.2)^2)/(nrow(politeness)-2)),  
S_res5.1 = sqrt(sum(resid(m5.2)^2)/(nrow(politeness)-2)),
S_res3.4 = sqrt(sum(resid(m3.4)^2)/(nrow(politeness)-2)))

anova(m3.4, m5.1, m5.2)
```


3)  Choose the model that you think describe the data the best - and write a short report on the main findings based on this model. At least include the following:
 i. describe what the dataset consists of  
  ii. what can you conclude about the effect of gender and attitude on pitch (if anything)?  
  iii. motivate why you would include separate intercepts for subjects and scenarios (if you think they should be included)  
  iv. describe the variance components of the second level (if any)  
  v. include a Quantile-Quantile plot of your chosen model 
  
# My answer to all of the above
I have selected the model 5.1 (f0mn ~ gender + attitude + (1|subject) + (1|scenario))
My decision is based primary based on AIC R_res and RS. But theoretically it also makes sense
to include both random intercepts due to the study being repeated measure and some
variance being random/unsystematic. attitude furthermore seems like an important 
addition to the model as specific attitudes are correlated with pitch frequency
(See imaginary study). However the interaction between gender:attitude doesn't add
any explaining to the model. 

```{r}
summary(m5.1)
MuMIn::r.squaredGLMM(m5.1)
#check assumptions
plot(m5.1)
```


```{r}
qqnorm(resid(m5.1))
qqline(resid(m5.1))
ggplot(politeness, aes(x= f0mn)) + geom_histogram()
```
â€œWe used R (R Core Team, 2019) and lmerTest (Kuznetsova, Brockhoff and Christensen, 2017) to perform a linear mixed effects analysis of the relationship between f0mn, gender
and attitude. As random effects, we had intercepts for subjects, and scenario.

Both fixed and random effects accounted for roughly 82% of the variance in the
f0mn variable with random effects proportion being 12.7%. 
Visual inspection shows that both the qqplot and histogram violates
the assumption of a mixed effect linear model. The more robust generalized mixed
effect model with a link function would be preferred. But as did was not the task
such model was not constructed. 

f0mn was found to be significantly modulated by gender. $\beta_2 = -115, SE = 12.16, p<0.05$
Attitude also showed a significant modulating of f0mn $\beta_1 = -14.8, SE = 4, p<0.05$

  