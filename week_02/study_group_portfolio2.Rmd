---
title: "practical_exercise_2, Methods 3, 2021, autumn semester"
author: 'Sara Krejberg, Niels A. Krogsgaard, Sigurd F. Sørensen, Laura W. Paaby'
date: "29/9 - 2021"
output: html_document
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r}
pacman::p_load(tidyverse, lmerTest)
```

# Assignment 1: Using mixed effects modelling to model hierarchical data
In this assignment we will be investigating the _politeness_ dataset of Winter and Grawunder (2012) and apply basic methods of multilevel modelling. 

## Dataset
The dataset has been shared on GitHub, so make sure that the csv-file is on your current path. Otherwise you can supply the full path.

```{r}
politeness <- read.csv('politeness.csv') ## read in data
```

# Exercises and objectives
The objectives of the exercises of this assignment are:  
1) Learning to recognize hierarchical structures within datasets and describing them  
2) Creating simple multilevel models and assessing their fitness  
3) Write up a report about the findings of the study  

REMEMBER: In your report, make sure to include code that can reproduce the answers requested in the exercises below  
REMEMBER: This assignment will be part of your final portfolio

## Exercise 1 - describing the dataset and making some initial plots

1) Describe the dataset, such that someone who happened upon this dataset could understand the variables and what they contain  

*The dataset is a result of a study, which investigated the properties of formal and informal speech register. To do so different variables were measured, to enlighten what might characterize the register. The variables are what we see in the dataset: 
**f0mn**: the mean frequency of the pitch of the sentence uttered i Hz. 
**scenarios**: the number indicates what specific scenario the subject has been presented with in that observation, e.g. “You are in the professor's office and want to ask for a letter of recommendation” (Grawunder & Winter et al., 2011, p. 2) is an example of a scenario. I must add that this specific scenario was aimed at producing formal speech, while a scenario much the same was aimed at producing informal speech.
**gender**: the gender of the participant (f = female, m = male)
**total_duration**: duration of response in seconds ,
**hiss_count**: the amount of loud hissing breath intake (hiss_count). T
**attitude**: is either polite or informal, which are variables the scenarios are categorized by. 
The subjects are the participants of the study - F females whereas M is male.*

    i. Also consider whether any of the variables in _politeness_ should be encoded as factors or have the factor encoding removed. Hint: ```?factor```  
    
```{r}
#investigating the data
ls.str(politeness)

```


```{r}
#making gender, attitude and scenaruo into facter and adding them to the dataframe:
attitude.f = as.factor(politeness$attitude) 
gender.f = as.factor(politeness$gender)
scenario.f = as.factor(politeness$scenario)

politeness <- politeness %>% 
  mutate(attitude.f, gender.f, scenario.f) 


```
    
  
2) Create a new data frame that just contains the subject _F1_ and run two linear models; one that expresses _f0mn_ as dependent on _scenario_ as an integer; and one that expresses _f0mn_ as dependent on _scenario_ encoded as a factor  

```{r}
#making a dataframe only for the first subject (F1)
F1_df <- politeness %>%
  filter(subject == 'F1')


## Running the two linear models
#model 1 with scenario as integer:
F1_model1 <- lm(f0mn ~ scenario, data = F1_df)
#model 2 with scenario as factor
F1_model2 <- lm(f0mn ~ scenario.f, data = F1_df)

summary(F1_model1)
summary(F1_model2)
```

    i. Include the model matrices, $X$ from the General Linear Model, for these two models in your report and describe the different interpretations of _scenario_ that these entail
```{r}
#making a model matrix for each model:

X1 <- model.matrix(F1_model1) #integer model
X2 <- model.matrix(F1_model2) #factor model

```
*The design matrix for the model with scenario as an integer take scenario as a continuous variable where going from 2 to 4 is some meaningful doubling. We therefore not only take the scenarios as having some kind of meaningful order, but also take scenario 6 is being double the amount of scenario 3, all in all treating it as a continuous variable (which is of course wrong, since we have no expectation that f0mn will change systematically with increasing scenario number).*

*The design matrix for the model with scenario as a factor take scenario to be a categorical variable. In the design matrix we can see all the different observations of scenario coded as dummy variables, so every factor level has its own beta-value connected to it. Scenario 1 is "excluded" since that will be the intercept.*


**Description of both models and matrixes:**
*the factored model:*
The design matrix is a [14x7] matrix, so we will get the following $\beta_{0-6}$. 
This is also shown by the summary of a our linear regression model.
*A simple regression f0mn ~ scenario was conducted. Scenario seemed to account
for 36.4% of the variance in f0mn following adjusted R^2. 
F(1,6) = 2.24, p >0.5) all beta values were insignificant. We only have 14
observations spread out over 7 different levels. So the high p-value is most likely
due to sample-size. A further power-analysis could show the required sample size required.

*the integer model:*
Now that scenario is encoded as an integer the design matrix will be a [14x2] matrix.
Our model will therefore only give us $\beta_{0-1}$ and not a $\beta$ for each
level of scenario as done in the previous model. This model assumes that there is
a constant increment of f0mn following a "increase" in scenario (if you can even talk about
a unit increase of scenario). This would only make sense if scenarios were ordered
as getting harder and harder. The model is again f0mn ~ scenario 
F(1,12) = 2.231, p>0.5) with an adjusted $R^2$ = 0.0865 showing an explained
variance of 8.65% ($\beta_1$ = -6.886, SE = 4.6, t = -1.5, p>0.16.) Again such a
small sample size might be tricky to work with.



    
    ii. Which coding of _scenario_, as a factor or not, is more fitting?
*In this context it is only appropriate to code scenario as a factor. The reasons are given in the previous exercise.*

    
3) Make a plot that includes a subplot for each subject that has _scenario_ on the x-axis and _f0mn_ on the y-axis and where points are colour coded according to _attitude_
    i. Describe the differences between subjects

```{r}
politeness %>% 
    ggplot(aes(scenario.f, f0mn, color = attitude.f)) + geom_point() +
    facet_wrap(~subject) +
  theme_bw() +
  xlab("Scenarios") +
  ylab("Frequency") +
  ggtitle("Subplot for Each Subject") 


```
*There seem to be a lower baseline/intercept given that you're a male. Attitude doesn't seem to have an large effect on f0mn. So an idea could be to add Gender as a fixed effect and subject as a random intercept as there is also individual variance within the gender category.*     
    
    
    
    
## Exercise 2  - comparison of models


1) Build four models and do some comparisons
    i. a single level model that models _f0mn_ as dependent on _gender_
    ii. a two-level model that adds a second level on top of i. where unique intercepts are modelled for each _scenario_
    iii. a two-level model that only has _subject_ as an intercept 
    iv. a two-level model that models intercepts for both _scenario_ and _subject_
    v. which of the models has the lowest residual standard deviation, also compare the Akaike Information Criterion `AIC`?
    vi. which of the second-level effects explains the most variance?
    
```{r}
#i
model1 <- lm(f0mn ~ gender.f, data = politeness)

#ii
model2 <- lmer(f0mn ~ gender.f + (1 | scenario.f), data = politeness, REML = FALSE)
                        
#iii
model3 <- lmer(f0mn ~ gender.f + (1 | subject), data = politeness, REML = FALSE)

#iv
model4 <- lmer(f0mn ~ gender.f + (1 | scenario.f) + (1|subject), data = politeness, REML = FALSE)

```   
    
Comparison of models by the Akaike Information Criterion:
```{r}
#v
AIC(model1, model2, model3, model4)
```
Comparing the residual standard deviation of the models:
```{r}
#v
sigma(model1)
sigma(model2)
sigma(model3)
sigma(model4)
```
*Looking at both the standard deviation and the information criterion, we find that the model4 is the best performing model, since it has the smallest value both in AIC and RSD.*


```{r}
#vi the most variance explained by the effects (scenario or subject):
pacman::p_load(MuMIn)

r.squaredGLMM(model2)
r.squaredGLMM(model3)
r.squaredGLMM(model4)

```




*model2 showed the best variance explained purely by fixed effects, 68,17%, with scenario as a random intercept.*
*We can conclude in model3 that adding subject as random intercept rather than scenario explains more of the variance but also has more shared variance with our fixed effect gender.* 
*Model4 (f0mn ~ gender + (1|scenario) + (1|subject)) showed most explained variance with 80% of the variance being accounted for by both fixed and random effects.* 





    
2) Why is our single-level model bad?
*(the single level model is bad, since it violates the most important assumption of independence)*

    i. create a new data frame that has three variables, _subject_, _gender_ and _f0mn_, where _f0mn_ is the average of all responses of each subject, i.e. averaging across _attitude_ and_scenario_
    
```{r}
#making a new dataframe with the selected variables: 
politeness_sel <- politeness %>% 
  filter(!is.na(f0mn)) %>% #making sure there is no NA in the new df
  select(f0mn,attitude,subject) %>% 
  group_by(subject) %>% 
  summarise(f0mn_mean = mean(f0mn)) 

politeness_sel <- politeness_sel %>% #adding the gender to the dataframe
  mutate(gender = if_else(grepl("F", politeness_sel$subject, ignore.case = T),"F","M")) %>% 
  mutate(gender = as.factor(gender))


```


    ii. build a single-level model that models _f0mn_ as dependent on _gender_ using this new dataset
```{r}
#builing single-level model 
ms <- lm(f0mn_mean ~ gender, data = politeness_sel)
```


    iii. make Quantile-Quantile plots, comparing theoretical quantiles to the sample quantiles) using `qqnorm` and `qqline` for the new single-level model and compare it to the old single-level model (from 1).i). Which model's residuals ($\epsilon$) fulfil the assumptions of the General Linear Model better?)
```{r}
#the new single model 
qqnorm(resid(ms))
qqline(resid(ms), col = 'lightblue')

#The old single model 
qqnorm(resid(model1))
qqline(resid(model1), col = 'green')
```
*Looking at the data we how the ms model doesn't fit the line very well, however it does not seemed skewed. The model1 seems a bit skewed, and fits the line worse. This could properly have been fixed by trimming the data/remove outliers.*

    
    iv. Also make a quantile-quantile plot for the residuals of the  multilevel model with two intercepts. Does it look alright?
```{r}
#The multilevel model (model 4)
qqnorm(resid(model4))
qqline(resid(model4), col = 'pink')
```
*In a perfect world, this model would have made the datapoints fit the line better. This doesn't seem to be the case, and the residuals are still right skewed. They don't follow the normal distribution perfectly. However this is the least important of the assumptions, (normality of residuals).*

  
3) Plotting the two-intercepts model
    i. Create a plot for each subject, (similar to part 3 in Exercise 1), this time also indicating the fitted value for each of the subjects for each for the scenarios (hint use `fixef` to get the "grand effects" for each gender and `ranef` to get the subject- and scenario-specific effects)

```{r}

fitted <- fitted(model4) #making the fitted values 

politeness_una <- politeness %>% 
  filter(!is.na(f0mn)) %>%  #making sure we have no NA's
  mutate(fitted) #adding the fitted values to the dataset 

politeness_una %>% 
  ggplot(aes(scenario.f, f0mn, color = attitude.f))+
  geom_point()+
  geom_point(aes(y = fitted), colour = 'black', size = 0.5)+
  facet_wrap(~subject) +
  theme_minimal()+
  xlab("Scenario")+
  ylab('Frequency') +
  ggtitle("Subplot for Each Subject") 


```


## Exercise 3 - now with attitude

1) Carry on with the model with the two unique intercepts fitted (_scenario_ and _subject_).
    i. now build a model that has _attitude_ as a main effect besides _gender_
```{r}
# the model to carry on with: model4 <- lmer(f0mn ~ gender.f + (1 | scenario.f) + (1|subject), data = politeness)
#the new model with both gender and attitude: 
model5 <- lmer(f0mn ~ gender.f + attitude.f + (1|scenario.f)+(1|subject), data = politeness, REML = FALSE)
```

    ii. make a separate model that besides the main effects of _attitude_ and _gender_ also include their interaction
    
```{r}
model6 <- lmer(f0mn ~ gender.f*attitude.f + (1|scenario.f)+(1|subject), data = politeness, REML = FALSE)
summary(model6)
```

    iii. describe what the interaction term in the model says about Korean men's pitch when they are polite relative to Korean women's pitch when they are polite (you don't have to judge whether it is interesting)  
  
**Understanding the output of the model:**   
*When males are asked  to be polite, their pitch will according to this be higher.* 
*The intercepts is for the female, when uttering the statement informal, where they here have the average pitch of 255 hz.*
*GenderfM is then when we go from female to male on the x ax,  we see how the average pitch decrease with 118 hz.*
*attitudef.pol, when we go from informal to polite does the average (of both females and males) pitch decrease with 17 hz. This is why need the interaction, so we can consider more than just the average*
*genderM:attitudepol: this is the interaction between gender and attitude, and it indicates that it decreases 5,5hz less for men than women. This means that the change in pitch for men are on -17.192+5.54 = -11.652, whereas the womens changes with -17.192 hz.*
*Summarizingly, both men and women decrease their pitch when going from informal to polite, but the male pitch does not decrease as much the women. *
    *(for the reader: the f just means that it is factors, a bit confusing considering the females - but  this is     not the case!)*

**Reporting the model:**
*The model f0mn ~ attitude:gender + (1|subject)+ (1|scenario)has an $R^2c$ 0.81 both attitude and gender showed a significant effect on f0mn ($\beta_1$(attitude_pol) = -17.2, SE = 5.4, p>0.05) and ($\beta_2$(genderM) = -119, SE = 12.8, p>0.05). Being polite and male lowers your frequency. Being both Male and Polite has an interaction effect of ($\beta_3$ = 5.5, SE = 8.24, p<0.05). Hereby concluding that there is a small positive insignificant interaction effect of being male and polite. The SE being proportional large compared to the effect size makes it very difficult to say anything meaningful.*


    
2) Compare the three models (1. gender as a main effect; 2. gender and attitude as main effects; 3. gender and attitude as main effects and the interaction between them. For all three models model unique intercepts for _subject_ and _scenario_) using residual variance, residual standard deviation and AIC.  
```{r}
#model4: gender as main effect 
summary(model4)
#model5: gender and attitudes as main effects
summary(model5)
#model6: gender and attitude as main effects and with an interaction between them
summary(model6)
```

```{r}
#comparison by AIC:
AIC(model4, model5, model6)
```

```{r}
#comparing by standard deviation of residuals
sigma(model4)
sigma(model5)
sigma(model6)
```

```{r}
#comparing by the residual variance:
sum(residuals(model4)^2)
sum(residuals(model5)^2)
sum(residuals(model6)^2)


```
*Considering the output of the comparisons, we suggest model 5: it is the simpler model and adding the interaction effect (model 6) makes almost no explanatory power, while being more complex.* 


3)  Choose the model that you think describe the data the best - and write a short report on the main findings based on this model. At least include the following:
  i. describe what the dataset consists of  
*The dataset used in this model consists of subject id, binary gender indication (F or M), scenario index (from 1 to 7 depending on what the scenario was), a variable indicating whether the text should be spoken in an formal/polite or informal tone, and a variable called f0mn basically stating the average frequency of the utterance in Hz. Besides these the data also consisted of total duration of utterances in seconds and count of hissing sounds but these are not relevant for the optimal model.*

  ii. what can you conclude about the effect of gender and attitude on pitch (if anything)?  
*f0mn was found to be significantly modulated by gender.* $\beta_2 = -115, SE = 12.16, p<0.05$
*Attitude also showed a significant modulating of f0mn* $\beta_1 = -14.8, SE = 4, p<0.05$


  iii. motivate why you would include separate intercepts for subjects and scenarios (if you think they should be included)  
**Subjects:** *these are only a sample of the total population. Because subject does not exhaust the population of interest (e.g. the whole Korean population) it should be modeled as a random effect. Also, each subject will express random variation caused by individual baselines and individual effects of formal vs. informal situation.*
  
**Scenario:** *Again, these scenarios does not exhaust the number of formal or informal scenarios that exist. It should be modeled as a random effect since we have no expectation of how the individual scenario will affect the pitch compared to the other scenarios. There are no preconceptions about any systematic differences between the scenarios, making them have idiosyncratic and random effects on pitch.*  
  
  
  iv. describe the variance components of the second level (if any)  
*Both fixed and random effects accounted for roughly 82% of the variance in the f0mn variable with random effects proportion being 12.7%. Visual inspection shows that both the qqplot and histogram violates the assumption of a mixed effect linear model. The more robust generalized mixed effect model with a link function would be preferred. But as it was not the task such model was not constructed.*   

  v. include a Quantile-Quantile plot of your chosen model  
```{r}
qqnorm(resid(model5))
qqline(resid(model5), col = 'aquamarine')
```

  
*We used R (R Core Team, 2019) and lmerTest (Kuznetsova, Brockhoff and Christensen, 2017) to perform a linear mixed effects analysis of the relationship between f0mn, gender and attitude. As random effects, we had intercepts for subjects, and scenario.*



